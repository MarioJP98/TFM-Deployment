{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f59e4829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn joblib pyarrow pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41dde9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(r\"C:\\Dataset\\v8_mlp.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ad92be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_0      968979\n",
       "f_1      968979\n",
       "f_2      968979\n",
       "f_3      968979\n",
       "f_4      968979\n",
       "f_5      968979\n",
       "label    968979\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "df.head(1)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59f9a1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.07856099\n",
      "Validation score: 0.981979\n",
      "Iteration 2, loss = 0.02492375\n",
      "Validation score: 0.992221\n",
      "Iteration 3, loss = 0.02092173\n",
      "Validation score: 0.992621\n",
      "Iteration 4, loss = 0.01974251\n",
      "Validation score: 0.993086\n",
      "Iteration 5, loss = 0.01805779\n",
      "Validation score: 0.980998\n",
      "Iteration 6, loss = 0.01832535\n",
      "Validation score: 0.996336\n",
      "Iteration 7, loss = 0.01690350\n",
      "Validation score: 0.995021\n",
      "Iteration 8, loss = 0.01672613\n",
      "Validation score: 0.995640\n",
      "Iteration 9, loss = 0.01609878\n",
      "Validation score: 0.986519\n",
      "Iteration 10, loss = 0.01509248\n",
      "Validation score: 0.993705\n",
      "Iteration 11, loss = 0.01578419\n",
      "Validation score: 0.991950\n",
      "Iteration 12, loss = 0.01485024\n",
      "Validation score: 0.995756\n",
      "Iteration 13, loss = 0.01478484\n",
      "Validation score: 0.997446\n",
      "Iteration 14, loss = 0.01538840\n",
      "Validation score: 0.995743\n",
      "Iteration 15, loss = 0.01423465\n",
      "Validation score: 0.996001\n",
      "Iteration 16, loss = 0.01410973\n",
      "Validation score: 0.996078\n",
      "Iteration 17, loss = 0.01401605\n",
      "Validation score: 0.993356\n",
      "Iteration 18, loss = 0.01400748\n",
      "Validation score: 0.992634\n",
      "Iteration 19, loss = 0.01358761\n",
      "Validation score: 0.995240\n",
      "Iteration 20, loss = 0.01366865\n",
      "Validation score: 0.990338\n",
      "Iteration 21, loss = 0.01338306\n",
      "Validation score: 0.993318\n",
      "Iteration 22, loss = 0.01282278\n",
      "Validation score: 0.996556\n",
      "Iteration 23, loss = 0.01298071\n",
      "Validation score: 0.997549\n",
      "Iteration 24, loss = 0.01241489\n",
      "Validation score: 0.997846\n",
      "Iteration 25, loss = 0.01220134\n",
      "Validation score: 0.992957\n",
      "Iteration 26, loss = 0.01218386\n",
      "Validation score: 0.995266\n",
      "Iteration 27, loss = 0.01231820\n",
      "Validation score: 0.997420\n",
      "Iteration 28, loss = 0.01278929\n",
      "Validation score: 0.992183\n",
      "Iteration 29, loss = 0.01265465\n",
      "Validation score: 0.995730\n",
      "Iteration 30, loss = 0.01198364\n",
      "Validation score: 0.991937\n",
      "Iteration 31, loss = 0.01206773\n",
      "Validation score: 0.997291\n",
      "Iteration 32, loss = 0.01185924\n",
      "Validation score: 0.995807\n",
      "Iteration 33, loss = 0.01210768\n",
      "Validation score: 0.996556\n",
      "Iteration 34, loss = 0.01235658\n",
      "Validation score: 0.995614\n",
      "Iteration 35, loss = 0.01148496\n",
      "Validation score: 0.996930\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 0.997564449214638\n",
      "F1: 0.9975624027737723\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "# 2. Features y labels\n",
    "# selecciona f_0, f_1, ...\n",
    "feat_cols = [c for c in df.columns if c.startswith(\"f_\")]\n",
    "X = df[feat_cols].astype(\"float32\").values\n",
    "y = df[\"label\"].astype(\"int64\").values\n",
    "\n",
    "# 3. Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. Definir MLP (Adam, ReLU, early stopping)\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",         # Adam como en el paper\n",
    "    alpha=1e-4,            # regularización L2\n",
    "    batch_size=256,\n",
    "    learning_rate_init=1e-3,\n",
    "    max_iter=100,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=10,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 5. Entrenar\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# 6. Evaluar\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1:\", f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaa5c143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en mlp_camelot_adam.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar modelo entrenado\n",
    "joblib.dump(mlp, \"mlp_camelot_adam.pkl\")\n",
    "print(\"Modelo guardado en mlp_camelot_adam.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aadb1bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9927    0.9963     16479\n",
      "           1     0.9986    0.9992    0.9989     31798\n",
      "           2     0.9989    1.0000    0.9995     10246\n",
      "           3     1.0000    0.9979    0.9989     27488\n",
      "           4     0.9949    0.9998    0.9973     19719\n",
      "           5     0.9972    0.9979    0.9975     19685\n",
      "           6     0.9996    0.9873    0.9934      9021\n",
      "           7     0.9967    1.0000    0.9983     16252\n",
      "           8     0.9928    1.0000    0.9964     14231\n",
      "           9     0.9996    0.9890    0.9943      9361\n",
      "          10     0.9952    0.9997    0.9974     19516\n",
      "\n",
      "    accuracy                         0.9976    193796\n",
      "   macro avg     0.9976    0.9967    0.9971    193796\n",
      "weighted avg     0.9976    0.9976    0.9976    193796\n",
      "\n",
      "[[16359     0     0     0     0     0     0    49     0     0    71]\n",
      " [    0 31772     0     0     0     3     0     0     0     0    23]\n",
      " [    0     0 10246     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0 27431     0    53     0     0     0     4     0]\n",
      " [    0     0     0     0 19715     0     4     0     0     0     0]\n",
      " [    0    40     0     1     0 19644     0     0     0     0     0]\n",
      " [    0     0    11     0   102     0  8906     2     0     0     0]\n",
      " [    0     0     0     0     0     0     0 16252     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0 14231     0     0]\n",
      " [    0     0     0     0     0     0     0     0   103  9258     0]\n",
      " [    0     3     0     0     0     0     0     3     0     0 19510]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66435f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar modelo\n",
    "mlp_loaded = joblib.load(\"mlp_camelot_adam.pkl\")\n",
    "\n",
    "# Cargar nuevas canciones ya con columnas f_0..f_n (mismo pipeline de features)\n",
    "df_new = pd.read_parquet(\n",
    "    \"/opt/bitnami/spark/datasets/nuevas_canciones_mlp.parquet\")\n",
    "feat_cols = [c for c in df_new.columns if c.startswith(\"f_\")]\n",
    "X_new = df_new[feat_cols].astype(\"float32\").values\n",
    "\n",
    "# Predicción\n",
    "pred_clusters = mlp_loaded.predict(X_new)\n",
    "probs = mlp_loaded.predict_proba(X_new)   # para Top-C clusters\n",
    "\n",
    "df_new[\"pred_cluster\"] = pred_clusters\n",
    "# Top-2 clusters con probas\n",
    "topC = 2\n",
    "top2 = np.argpartition(-probs, kth=topC-1, axis=1)[:, :topC]\n",
    "df_new[\"topC_clusters\"] = [list(row) for row in top2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46148958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-C clusters: [1, 3]\n",
      "Recs (MMR):\n",
      "        label\n",
      "2941        1\n",
      "776913      1\n",
      "697146      1\n",
      "913756      1\n",
      "232706      1\n",
      "175669      1\n",
      "194259      1\n",
      "477544      1\n",
      "613163      1\n",
      "555325      1\n",
      "482006      1\n",
      "738115      1\n",
      "875029      1\n",
      "224502      1\n",
      "210670      1\n",
      "584674      1\n",
      "475722      1\n",
      "173706      1\n",
      "516203      1\n",
      "386647      1\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Config ----------\n",
    "# tu catálogo plano (features + label)\n",
    "PARQUET_CATALOG = r\"C:\\Dataset\\v8_mlp.parquet\"\n",
    "MODEL_PATH = \"mlp_camelot_adam.pkl\"\n",
    "TOP_C = 2          # nº de clusters a expandir (paper-like)\n",
    "TOP_N = 200        # nº de candidatos iniciales tras coseno\n",
    "K_FINAL = 50       # tamaño final tras MMR\n",
    "LAMBDA_REL = 0.7   # trade-off relevancia/diversidad en MMR\n",
    "\n",
    "# ---------- Utilidades ----------\n",
    "\n",
    "\n",
    "def feature_columns(df: pd.DataFrame):\n",
    "    \"\"\" Detecta columnas f_0..f_n en orden correcto. \"\"\"\n",
    "    return [c for c in df.columns if c.startswith(\"f_\")]\n",
    "\n",
    "\n",
    "def cosine_sim_matrix(seed_vec: np.ndarray, M: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" Cosine(seed, cada fila de M). \"\"\"\n",
    "    seed_norm = np.linalg.norm(seed_vec)\n",
    "    M_norms = np.linalg.norm(M, axis=1)\n",
    "    denom = (seed_norm * M_norms)\n",
    "    denom[denom == 0] = 1e-12\n",
    "    return (M @ seed_vec) / denom\n",
    "\n",
    "\n",
    "def mmr_select(seed_vec: np.ndarray, cand_mat: np.ndarray, items_idx: np.ndarray, k=50, lambda_rel=0.7):\n",
    "    \"\"\"\n",
    "    MMR greedy: combina relevancia (cosine con seed) y diversidad\n",
    "    (máx. similitud con ya seleccionados). Devuelve índices seleccionados en orden.\n",
    "    \"\"\"\n",
    "    selected = []\n",
    "    selected_idx = []\n",
    "    if len(items_idx) == 0:\n",
    "        return selected_idx\n",
    "\n",
    "    # Pre-calc similitud de relevancia\n",
    "    rel = cosine_sim_matrix(seed_vec, cand_mat)\n",
    "\n",
    "    # Escoge el más relevante primero\n",
    "    best0 = int(np.argmax(rel))\n",
    "    selected_idx.append(items_idx[best0])\n",
    "    selected.append(cand_mat[best0])\n",
    "\n",
    "    # Iterativamente añade con MMR\n",
    "    while len(selected_idx) < min(k, len(items_idx)):\n",
    "        best_i, best_score = None, -1e9\n",
    "        for i in range(len(items_idx)):\n",
    "            if items_idx[i] in selected_idx:\n",
    "                continue\n",
    "            # diversidad: max similitud con ya seleccionados\n",
    "            max_sim = 0.0\n",
    "            for s in selected:\n",
    "                denom = (np.linalg.norm(cand_mat[i]) * np.linalg.norm(s))\n",
    "                if denom == 0:\n",
    "                    sim = 0.0\n",
    "                else:\n",
    "                    sim = float(np.dot(cand_mat[i], s) / denom)\n",
    "                if sim > max_sim:\n",
    "                    max_sim = sim\n",
    "            score = lambda_rel * rel[i] - (1 - lambda_rel) * max_sim\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_i = i\n",
    "        selected_idx.append(items_idx[best_i])\n",
    "        selected.append(cand_mat[best_i])\n",
    "    return selected_idx\n",
    "\n",
    "\n",
    "# ---------- Cargar modelo y catálogo ----------\n",
    "mlp = joblib.load(MODEL_PATH)\n",
    "catalog = pd.read_parquet(PARQUET_CATALOG)\n",
    "feat_cols = feature_columns(catalog)\n",
    "\n",
    "# ---------- 1) Seed: usa la \"canción inventada\" o una real del catálogo ----------\n",
    "# (A) Canción inventada (misma que arriba)\n",
    "d = mlp.n_features_in_\n",
    "rng = np.random.default_rng(123)\n",
    "seed_vec = rng.normal(0.0, 0.1, size=d).astype(\"float32\")\n",
    "\n",
    "# (B) Si quieres usar una seed real del catálogo:\n",
    "# seed_row = catalog.sample(1, random_state=7).iloc[0]\n",
    "# seed_vec = seed_row[feat_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "# ---------- 2) Top-C clusters por probabilidad ----------\n",
    "probs = mlp.predict_proba(seed_vec.reshape(1, -1))[0]\n",
    "topC_clusters = np.argsort(probs)[::-1][:TOP_C]   # p.ej. [7, 9]\n",
    "\n",
    "# ---------- 3) Candidatos de esos clusters ----------\n",
    "cand_mask = catalog[\"label\"].isin(topC_clusters)\n",
    "candidates = catalog.loc[cand_mask].copy()\n",
    "\n",
    "# Para evitar recomendar la propia seed, si fuese del catálogo:\n",
    "# si usaste (B), puedes excluir por ID/título/artist si tienes columnas\n",
    "# candidates = candidates[candidates[\"track_id\"] != seed_row[\"track_id\"]]\n",
    "\n",
    "# ---------- 4) Ranking por coseno ----------\n",
    "M = candidates[feat_cols].to_numpy(dtype=np.float32)\n",
    "sims = cosine_sim_matrix(seed_vec, M)\n",
    "order = np.argsort(sims)[::-1]\n",
    "topN_idx_local = order[:TOP_N]\n",
    "candidates_topN = candidates.iloc[topN_idx_local].copy()\n",
    "\n",
    "# ---------- 5) Diversificación MMR ----------\n",
    "# necesitamos volver a las posiciones globales\n",
    "items_idx_global = candidates_topN.index.to_numpy()\n",
    "cand_mat = candidates_topN[feat_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "mmr_indices_global = mmr_select(\n",
    "    seed_vec=seed_vec,\n",
    "    cand_mat=cand_mat,\n",
    "    items_idx=items_idx_global,\n",
    "    k=K_FINAL,\n",
    "    lambda_rel=LAMBDA_REL\n",
    ")\n",
    "\n",
    "playlist = catalog.loc[mmr_indices_global].copy()\n",
    "\n",
    "# ---------- 6) Mostrar resultado ----------\n",
    "cols_to_show = [c for c in [\"title\", \"artist\", \"label\"]\n",
    "                if c in playlist.columns]\n",
    "print(\"Top-C clusters:\", list(map(int, topC_clusters)))\n",
    "print(\"Recs (MMR):\")\n",
    "print(playlist[cols_to_show].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1195b395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
