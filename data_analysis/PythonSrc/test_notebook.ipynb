{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23eb1629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5_getters as GETTERS\n",
    "import h5py\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a039cfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist: b'Casual', Song: b\"I Didn't Mean To\", Year: 0, Duration: 218.93s\n"
     ]
    }
   ],
   "source": [
    "# Localiza un archivo de canción\n",
    "filename = glob.glob(\n",
    "    r'C:\\Users\\Mario\\Documents\\1.Estudios\\1.UNIR\\TFM\\Datasets\\millionsongsubset\\MillionSongSubset\\A\\A\\A\\TRAAAAW128F429D538.h5'\n",
    ")[0]\n",
    "\n",
    "# Abre el archivo\n",
    "h5 = GETTERS.open_h5_file_read(filename)\n",
    "\n",
    "# Obtén algunos datos\n",
    "artist_name = GETTERS.get_artist_name(h5)\n",
    "song_title = GETTERS.get_title(h5)\n",
    "year = GETTERS.get_year(h5)\n",
    "duration = GETTERS.get_duration(h5)\n",
    "\n",
    "print(\n",
    "    f\"Artist: {artist_name}, Song: {song_title}, Year: {year}, Duration: {duration:.2f}s\")\n",
    "\n",
    "h5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5739600f",
   "metadata": {},
   "source": [
    "#### 1. Crear la sesión con SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4d476e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize spark:\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# import pyspark\n",
    "# print(pyspark.__version__)\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MSD Recommender\") \\\n",
    "    .master(\"spark://localhost:7077\") \\\n",
    "    .config(\"spark.driver.host\", \"192.168.1.130\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"12g\") \\\n",
    "    .config(\"spark.executor.cores\", \"3\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75240a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5647417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "df_test = spark.range(10)  # 1 millón de filas\n",
    "print(df_test.count())  # Debe devolver 1,000,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629fc4ff",
   "metadata": {},
   "source": [
    "#### Anañizar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf11b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType\n",
    "\n",
    "import numpy as np\n",
    "import hdf5_getters as GETTERS\n",
    "import h5py\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd5e8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar ruta del dataset\n",
    "\n",
    "dataset_path = \"C:/Users/Mario/Documents/1.Estudios/1.UNIR/TFM/Datasets/millionsongsubset/MillionSongSubset\"\n",
    "file_paths = glob.glob(f\"{dataset_path}/**/*.h5\", recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51183695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+---+----+--------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+------------------+------------------+------------------+-------------------+------------------+--------------------+------------------+--------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+------------------+\n",
      "|  tempo|loudness| duration|key|mode|time_signature|           song_id|     timbre_mean_0|      timbre_std_0|     timbre_mean_1|      timbre_std_1|     timbre_mean_2|      timbre_std_2|      timbre_mean_3|      timbre_std_3|      timbre_mean_4|      timbre_std_4|     timbre_mean_5|      timbre_std_5|      timbre_mean_6|      timbre_std_6|       timbre_mean_7|      timbre_std_7|       timbre_mean_8|      timbre_std_8|     timbre_mean_9|      timbre_std_9|     timbre_mean_10|     timbre_std_10|     timbre_mean_11|     timbre_std_11|\n",
      "+-------+--------+---------+---+----+--------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+------------------+------------------+------------------+-------------------+------------------+--------------------+------------------+--------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+------------------+\n",
      "| 92.198| -11.197|218.93179|1.0| 0.0|           4.0|SOMZWCG12A8C13C480| 41.51277754891864|4.9445424861636464|15.662936148300714| 61.51997339337335|-5.789681771369724| 58.72095052632763|-0.7898444902162766| 54.47995639684928|-43.234903192584966|32.529316869317284|15.170947476828031| 37.56815900745458| 15.139038105046353| 27.00053438601485|  1.5050010298661167| 35.91573311467799|   6.589570545829048|27.005456594746708| 12.29855509783728| 24.12389233780607|-13.563280123583963|24.510618779447377|  5.442479917610713|17.726602302032287|\n",
      "|121.274|  -9.843|148.03546|6.0| 0.0|           4.0|SOCIWDW12A8C13D406| 43.07103636363632| 5.847454674436288|-4.035390909090912| 33.20336162425165|23.572292727272725|28.860205880821475| 12.923576363636357| 39.90195041394463|-2.5450363636363575|25.291304594384815| 5.052394545454545|29.122329106761285|  9.238150909090923|20.090048693568498|  -4.345974545454544|19.608092828015668|   5.224103636363631| 17.55375405459641|2.9356636363636377|16.797338198264015|-2.7526381818181807| 16.09334278248438| 1.7293963636363623|12.089104898332868|\n",
      "| 100.07|  -9.689|177.47546|8.0| 1.0|           1.0|SOXVLOJ12AB0189215|45.130814946619225| 4.231943455084958| -76.8233256227758| 50.00563550841421| 50.78732918149468| 47.88004425303696| 13.509893238434167| 47.09017558102692| -6.549258007117435| 32.40223142956248|-5.514241992882558| 26.58095510566428| 1.8851779359430594| 28.94485050785504|  -8.963729537366556|24.050853978626776|   3.759862989323842| 21.46642140872314|-5.117953736654802|18.026126999619205|  8.442069395017796|18.973604539307907|  4.477170818505343| 20.07895225861053|\n",
      "|119.293|  -9.013|233.40363|0.0| 1.0|           4.0|SONHOTT12A8C13493C|45.800255785627286|  6.50847469069157|41.148986601705204| 42.41131786925091| 57.59929476248478|33.781197082255545|  5.695314250913528|31.565086811907697| 0.9798928136419023|29.085176299967728|-7.360075517661389|   22.028813052035|-10.917191230207054|22.099069173936204|-0.46227161997563915|17.488866480917718|-0.29941047503045176| 25.67803452823948|-2.340377588306943|15.123002446682744|0.26161632155907566|12.489488957876443|-2.4275980511571236|18.634074343652564|\n",
      "|129.738|  -4.501|209.60608|2.0| 1.0|           4.0|SOFSOCN12A8C143F5D| 50.25155423476959| 4.227845209419915|27.845583952451705|22.555184670048927|47.091303120356585| 39.16986879231001| 11.080035661218442|30.454118747522124|-43.505350668647836| 28.25126808839106|-17.99725260029719|23.275417278162738| -5.284150074294206|20.070394998887185| -11.754643387815745|15.137500984053425|   10.51285141158989|13.721607772597004|2.1924576523031254| 13.08202427621625|  5.448426448737002|14.556299798152125| 1.7045156017830607|10.923347281838689|\n",
      "+-------+--------+---------+---+----+--------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+------------------+------------------+------------------+-------------------+------------------+--------------------+------------------+--------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lista para guardar los features\n",
    "data = []\n",
    "metadata_list = []  # OJO cambiamos el nombre de la lista de metadatos\n",
    "\n",
    "\n",
    "def extract_features(path):\n",
    "    try:\n",
    "        h5 = GETTERS.open_h5_file_read(path)\n",
    "        segments_timbre = GETTERS.get_segments_timbre(h5)\n",
    "        if segments_timbre is None or len(segments_timbre) == 0:\n",
    "            timbre_mean = [0.0] * 12\n",
    "            timbre_std = [0.0] * 12\n",
    "        else:\n",
    "            timbre_mean = np.mean(segments_timbre, axis=0).tolist()\n",
    "            timbre_std = np.std(segments_timbre, axis=0).tolist()\n",
    "\n",
    "        features = {\n",
    "            'tempo': float(GETTERS.get_tempo(h5)),\n",
    "            'loudness': float(GETTERS.get_loudness(h5)),\n",
    "            'duration': float(GETTERS.get_duration(h5)),\n",
    "            'key': float(GETTERS.get_key(h5)),\n",
    "            'mode': float(GETTERS.get_mode(h5)),\n",
    "            'time_signature': float(GETTERS.get_time_signature(h5)),\n",
    "            'song_id': GETTERS.get_song_id(h5).decode('utf-8')\n",
    "        }\n",
    "\n",
    "        for i in range(12):\n",
    "            features[f'timbre_mean_{i}'] = timbre_mean[i]\n",
    "            features[f'timbre_std_{i}'] = timbre_std[i]\n",
    "\n",
    "        song_id = GETTERS.get_song_id(h5).decode('utf-8')\n",
    "        title = GETTERS.get_title(h5).decode('utf-8')\n",
    "        artist = GETTERS.get_artist_name(h5).decode('utf-8')\n",
    "\n",
    "        meta = {\n",
    "            'song_id': song_id,\n",
    "            'title': title,\n",
    "            'artist': artist\n",
    "        }\n",
    "\n",
    "        h5.close()\n",
    "\n",
    "        return features, meta\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando el fichero: {path} --> {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# Recorremos los ficheros uno a uno\n",
    "for path in file_paths:\n",
    "    result, meta = extract_features(path)\n",
    "    if result is not None:\n",
    "        data.append(result)\n",
    "    if meta is not None:\n",
    "        metadata_list.append(meta)\n",
    "\n",
    "# Convertimos las listas a pandas\n",
    "df_pd = pd.DataFrame(data)\n",
    "df_meta = pd.DataFrame(metadata_list)\n",
    "\n",
    "# Guardamos los metadatos\n",
    "df_meta.to_csv(\"songs_metadata.csv\", index=False)\n",
    "\n",
    "# Y lo convertimos a DataFrame de PySpark\n",
    "df = spark.createDataFrame(df_pd)\n",
    "\n",
    "# Visualizamos los primeros registros\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c02db8",
   "metadata": {},
   "source": [
    "#### Entrenar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50d5b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "feature_cols = ['tempo', 'loudness', 'duration', 'key', 'mode', 'time_signature'] + \\\n",
    "               [f'timbre_mean_{i}' for i in range(12)] + \\\n",
    "               [f'timbre_std_{i}' for i in range(12)]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_vec\")\n",
    "df_assembled = assembler.transform(df)\n",
    "\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features_vec\", outputCol=\"scaled_features\")\n",
    "scaler_model = scaler.fit(df_assembled)\n",
    "df_scaled = scaler_model.transform(df_assembled)\n",
    "\n",
    "\n",
    "kmeans = KMeans(featuresCol='scaled_features',\n",
    "                predictionCol='cluster_id', k=20, seed=42)\n",
    "model = kmeans.fit(df_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44e23fa",
   "metadata": {},
   "source": [
    "#### Recomendación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2c52cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La nueva canción ha sido asignada al cluster: 13\n",
      "+------------------+\n",
      "|           song_id|\n",
      "+------------------+\n",
      "|SOIJXXM12A8C1416D6|\n",
      "|SOTUBVH12AB018D2EC|\n",
      "|SOFGQAP12AB0185946|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.clustering import KMeansModel\n",
    "\n",
    "# Supongamos que tienes ya definido:\n",
    "# model, scaler_model, assembler, df_scaled\n",
    "\n",
    "# 1️⃣ Simulamos la nueva canción\n",
    "new_song = {\n",
    "    'tempo': 120.0,\n",
    "    'loudness': -5.0,\n",
    "    'duration': 210.0,\n",
    "    'key': 2.0,\n",
    "    'mode': 1.0,\n",
    "    'time_signature': 4.0,\n",
    "    'song_id': 'NEW_SONG_ID'\n",
    "}\n",
    "\n",
    "# Simulamos timbre features\n",
    "for i in range(12):\n",
    "    new_song[f'timbre_mean_{i}'] = np.random.uniform(-50, 50)\n",
    "    new_song[f'timbre_std_{i}'] = np.random.uniform(10, 50)\n",
    "\n",
    "# 2️⃣ Convertimos a Spark DataFrame\n",
    "new_song_df_pd = pd.DataFrame([new_song])\n",
    "new_song_df = spark.createDataFrame(new_song_df_pd)\n",
    "\n",
    "# 3️⃣ Ensamblamos y escalamos usando el pipeline original\n",
    "new_song_vec = assembler.transform(new_song_df)\n",
    "new_song_scaled = scaler_model.transform(new_song_vec)\n",
    "\n",
    "# 4️⃣ Hacemos la predicción de cluster\n",
    "new_song_pred = model.transform(new_song_scaled)\n",
    "predicted_cluster = new_song_pred.select(\n",
    "    \"cluster_id\").collect()[0][\"cluster_id\"]\n",
    "\n",
    "print(f\"La nueva canción ha sido asignada al cluster: {predicted_cluster}\")\n",
    "\n",
    "# 5️⃣ Buscamos canciones del dataset original en el mismo cluster\n",
    "\n",
    "# Si no habías guardado los clusters en el df original:\n",
    "df_with_cluster = model.transform(df_scaled)\n",
    "\n",
    "# Filtramos por el mismo cluster\n",
    "similar_songs = df_with_cluster.filter(\n",
    "    df_with_cluster.cluster_id == predicted_cluster)\n",
    "\n",
    "# Mostramos algunas recomendaciones (por ejemplo 3)\n",
    "similar_songs.select(\"song_id\").limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e393b07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                song_id             title          artist\n",
      "69   SOIJXXM12A8C1416D6  Rosemary Recalls   Bruce Rowland\n",
      "85   SOTUBVH12AB018D2EC  Indian Love Call    Slim Whitman\n",
      "175  SOFGQAP12AB0185946    Dearly Beloved  Norrie Paramor\n"
     ]
    }
   ],
   "source": [
    "metadata_df = pd.read_csv(\"songs_metadata.csv\")\n",
    "\n",
    "# Supongamos que estos son los song_ids recomendados que has obtenido de tu modelo\n",
    "recommended_song_ids = [row['song_id']\n",
    "                        for row in similar_songs.select(\"song_id\").limit(3).collect()]\n",
    "\n",
    "\n",
    "# Filtramos los metadatos para obtener nombre de la canción y artista\n",
    "recommended_songs = metadata_df[metadata_df['song_id'].isin(\n",
    "    recommended_song_ids)]\n",
    "\n",
    "# Mostramos el resultado\n",
    "print(recommended_songs[['song_id', 'title', 'artist']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694b23f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
