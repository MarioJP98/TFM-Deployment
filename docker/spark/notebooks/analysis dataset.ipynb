{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f43afb1-ebb2-47d7-8628-4ec6ad2fcce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5_getters as GETTERS\n",
    "import h5py\n",
    "import glob\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType\n",
    "\n",
    "import numpy as np\n",
    "import hdf5_getters as GETTERS\n",
    "import h5py\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c087d2e6-16d1-490f-8f44-9a6b9b0592ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: job.local.dir\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/25 17:18:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/25 17:18:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     1|\n",
      "|     2|\n",
      "|     3|\n",
      "|     4|\n",
      "|     5|\n",
      "|     6|\n",
      "|     7|\n",
      "|     8|\n",
      "|     9|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('XML ETL') \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config('job.local.dir', 'file:/models/music-recommender-model') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.range(10).toDF(\"number\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72db8e3-88e7-47fa-8fd7-7e1ae2fb740a",
   "metadata": {},
   "source": [
    "#### Sacar CSV del DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39135801-1bbc-4965-aa0a-e826bdec2191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hdf5_getters as GETTERS\n",
    "\n",
    "dataset_path = \"/opt/bitnami/spark/datasets/\"\n",
    "file_paths = glob.glob(f\"{dataset_path}/**/*.h5\", recursive=True)\n",
    "file_paths = file_paths\n",
    "\n",
    "def extract_features(path):\n",
    "    try:\n",
    "        h5 = GETTERS.open_h5_file_read(path)\n",
    "\n",
    "        features = {\n",
    "            'track_id': GETTERS.get_track_id(h5).decode('utf-8'),\n",
    "            'song_id': GETTERS.get_song_id(h5).decode('utf-8'),\n",
    "            'title': GETTERS.get_title(h5).decode('utf-8'),\n",
    "            'artist_name': GETTERS.get_artist_name(h5).decode('utf-8'),\n",
    "            'year': GETTERS.get_year(h5),\n",
    "            'duration': float(GETTERS.get_duration(h5)),\n",
    "            'tempo': float(GETTERS.get_tempo(h5)),\n",
    "            'key': int(GETTERS.get_key(h5)),\n",
    "            'mode': int(GETTERS.get_mode(h5)),\n",
    "            'time_signature': int(GETTERS.get_time_signature(h5)),\n",
    "            'loudness': float(GETTERS.get_loudness(h5)),\n",
    "            'danceability': float(GETTERS.get_danceability(h5)),\n",
    "            'energy': float(GETTERS.get_energy(h5)),\n",
    "            'song_hotttnesss': float(GETTERS.get_song_hotttnesss(h5)),\n",
    "            'artist_hotttnesss': float(GETTERS.get_artist_hotttnesss(h5)),\n",
    "            'artist_familiarity': float(GETTERS.get_artist_familiarity(h5))\n",
    "        }\n",
    "\n",
    "        h5.close()\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando el fichero: {path} --> {e}\")\n",
    "        return None\n",
    "\n",
    "# Cargar todos los datos en un DataFrame\n",
    "data = []\n",
    "for path in file_paths:\n",
    "    result = extract_features(path)\n",
    "    if result:\n",
    "        data.append(result)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"muestra_million_song_filtrada.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c965ee-71e3-46cf-8c45-5a5dcc084470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sweetviz as sv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"muestra_million_song_filtrada.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01effa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\majimenez\\AppData\\Local\\anaconda3\\envs\\TFM-UNIR\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 52.88it/s]0<00:00, 23.00it/s, Describe variable: artist_familiarity]\n",
      "Summarize dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:06<00:00, 12.83it/s, Completed]                                     \n",
      "Generate report structure: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.44s/it]\n",
      "Render HTML: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.79s/it]\n",
      "Export report to file: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 31.45it/s]\n"
     ]
    }
   ],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c6ed64-3bce-4e12-bf20-3ea1b8553361",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m.columns:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“Œ Columna: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(df[col].value_counts())\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"\\nðŸ“Œ Columna: {col}\")\n",
    "    print(df[col].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1830c-eb71-4ccf-bda3-f586182902b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
