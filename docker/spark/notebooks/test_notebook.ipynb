{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23eb1629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5_getters as GETTERS\n",
    "import h5py\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a039cfbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Localiza un archivo de canción\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m filename = \u001b[43mglob\u001b[49m\u001b[43m.\u001b[49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataset\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mA\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mA\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mA\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mTRAAAAW128F429D538.h5\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Abre el archivo\u001b[39;00m\n\u001b[32m      7\u001b[39m h5 = GETTERS.open_h5_file_read(filename)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Localiza un archivo de canción\n",
    "filename = glob.glob(\n",
    "    r'dataset\\A\\A\\A\\TRAAAAW128F429D538.h5'\n",
    ")[0]\n",
    "\n",
    "# Abre el archivo\n",
    "h5 = GETTERS.open_h5_file_read(filename)\n",
    "\n",
    "# Obtén algunos datos\n",
    "artist_name = GETTERS.get_artist_name(h5)\n",
    "song_title = GETTERS.get_title(h5)\n",
    "year = GETTERS.get_year(h5)\n",
    "duration = GETTERS.get_duration(h5)\n",
    "\n",
    "print(\n",
    "    f\"Artist: {artist_name}, Song: {song_title}, Year: {year}, Duration: {duration:.2f}s\")\n",
    "\n",
    "h5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5739600f",
   "metadata": {},
   "source": [
    "#### 1. Crear la sesión con SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4d476e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     1|\n",
      "|     2|\n",
      "|     3|\n",
      "|     4|\n",
      "|     5|\n",
      "|     6|\n",
      "|     7|\n",
      "|     8|\n",
      "|     9|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize spark:\n",
    "from pyspark.sql import SparkSession\n",
    "# import findspark\n",
    "# findspark.init()\n",
    "\n",
    "import pyspark\n",
    "# print(pyspark.__version__)\n",
    "# findspark.init(\"C:\\spark\\spark-3.5.1-bin-hadoop3\\spark-3.5.1-bin-hadoop3\")\n",
    "\n",
    "\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"MSD Recommender\") \\\n",
    "#     .master(\"spark://192.168.1.130:7077\") \\\n",
    "#     # .config(\"spark.driver.host\", \"192.168.1.130\") \\\n",
    "#     .config(\"spark.driver.memory\", \"4g\") \\\n",
    "#     .config(\"spark.executor.memory\", \"12g\") \\\n",
    "#     .config(\"spark.executor.cores\", \"3\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"MillionSongProcessing\") \\\n",
    "#     .master(\"spark://spark-master:7077\") \\\n",
    "#     .getOrCreate()\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('XML ETL') \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config('job.local.dir', 'file:/models/music-recommender-model') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.range(10).toDF(\"number\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75240a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5647417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "df_test = spark.range(10)  # 1 millón de filas\n",
    "print(df_test.count())  # Debe devolver 1,000,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629fc4ff",
   "metadata": {},
   "source": [
    "#### Anañizar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf11b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType\n",
    "\n",
    "import numpy as np\n",
    "import hdf5_getters as GETTERS\n",
    "import h5py\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd5e8cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/bitnami/spark/datasets/MillionSongSubset/A/E/E/TRAEEOQ128F9309BC0.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/E/TRAEEGA128F4272FF8.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/E/TRAEEGO12903CF7D27.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/E/TRAEEBP128EF3673A7.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/E/TRAEELW128F933D255.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/E/TRAEELO128F425BD8F.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/E/TRAEEMP128F92F4B9C.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/G/TRAEGRU128F9358874.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/G/TRAEGGV128F92F29B2.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/G/TRAEGMN128F42690CD.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/G/TRAEGUL128E078B0C1.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/G/TRAEGAZ128F426240C.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/G/TRAEGJE128F42656F1.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/G/TRAEGBE128F4284973.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/G/TRAEGRF128F426B2D2.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/G/TRAEGRR128F422285F.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/G/TRAEGDO128F42705BF.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/G/TRAEGFX12903CF8E7B.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/G/TRAEGMO128F146D5F6.h5', '/opt/bitnami/spark/datasets/MillionSongSubset/A/E/G/TRAEGKP12903CBB66B.h5']\n"
     ]
    }
   ],
   "source": [
    "# Cargar ruta del dataset\n",
    "\n",
    "dataset_path = \"/opt/bitnami/spark/datasets/MillionSongSubset\"\n",
    "file_paths = glob.glob(f\"{dataset_path}/**/*.h5\", recursive=True)\n",
    "#Usando solo 3 paths\n",
    "file_paths = file_paths[:20]\n",
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51183695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+----+----+--------------+------------------+------------------+-----------------+-------------------+------------------+-------------------+------------------+-------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+------------------+\n",
      "|  tempo|loudness| duration| key|mode|time_signature|           song_id|     timbre_mean_0|     timbre_std_0|      timbre_mean_1|      timbre_std_1|      timbre_mean_2|      timbre_std_2|      timbre_mean_3|      timbre_std_3|     timbre_mean_4|      timbre_std_4|      timbre_mean_5|      timbre_std_5|      timbre_mean_6|      timbre_std_6|      timbre_mean_7|      timbre_std_7|     timbre_mean_8|      timbre_std_8|     timbre_mean_9|      timbre_std_9|     timbre_mean_10|     timbre_std_10|    timbre_mean_11|     timbre_std_11|\n",
      "+-------+--------+---------+----+----+--------------+------------------+------------------+-----------------+-------------------+------------------+-------------------+------------------+-------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+------------------+\n",
      "|100.296| -14.088|110.88934| 0.0| 0.0|           4.0|SOZECOE12AB017E615| 38.62859947643981|5.356287378976018|-101.03716492146597| 64.34570506271035| 27.049188481675404| 58.32669723112375|-1.6972146596858637| 47.09515469765234|21.343900523560208| 34.09278408844165| 15.569753926701566|36.683589576283666| -28.51487696335078|31.933875264135818|  4.463628272251304| 30.15178147998541| 22.10791361256545| 26.86277506521953| 7.504044502617803|26.022637808626587|-1.0602984293193713| 23.72026680716484|12.031910994764385| 23.74240463331764|\n",
      "|121.968|   -6.01|241.52771|11.0| 1.0|           4.0|SOXNSGB12A8C1396F1|44.535513000000044|5.478194661549649|          34.774147| 47.79820877687145|-3.3423789999999984|  47.2523564346727| 13.590332999999994| 62.78621346850048| 7.593021999999999| 37.52319802156417| 15.685361999999996| 44.94884628229024| 0.2800949999999996|29.522299127642054|  8.233494000000011|28.544652363130364| 2.409291999999998|23.649129849251032|11.965605000000007|23.780341794830765|          -7.616618|26.882983383212462|-9.606646000000014|22.849809052214958|\n",
      "|146.913| -11.027|177.57995| 7.0| 0.0|           1.0|SOGXWRE12AC468BE24|44.601593247588404|4.480842603870592|  44.04050803858517|31.206377005139693|   -3.5620884244373|25.259863374364052| -19.09931189710611| 29.28065459926128|4.8730369774919575|27.001562848901884|-14.241966237942117|22.750933922821634| -6.562429260450157|25.513166273507842|-0.6424887459807057|17.992917176935112|14.028934083601287|  19.8787722324577|3.3159839228295893|15.634624963180013|  -5.41135369774919|13.246051473316134| 5.725453376205784|17.314717115634608|\n",
      "|109.051| -15.586|541.23057| 9.0| 1.0|           4.0|SOIJPPR12A6D4F3945| 36.03285844748856|8.946115181246396|-109.42725114155256| 43.41483733127256| 103.44874657534241| 57.25723483577007| 3.8192739726027414|41.820336318309735|-23.84902511415523| 43.84637421670602| -9.415046803652974|18.279840506904183|-36.538407534246595|26.305825608843985|-5.5869063926940665|19.973966921591842| 23.75780251141551|31.319411468437018| 5.748410958904105|11.500391933665409| 0.7848915525114164|15.175306566253994|-4.383398401826487|19.765696755908383|\n",
      "| 87.897|  -9.532|142.86322| 1.0| 1.0|           4.0|SOMUYIL12AB0184EE2| 41.28385321100916|4.325701506084002|  9.338308256880746| 46.54334964716628| 0.4139944954128427|43.906155756893526|  3.009515596330276| 56.59037601487377|-16.11785504587156|27.283615249414268|-3.2823100917431174| 27.26093548498817| -8.804996330275218|21.270836474280532| -6.034921100917432| 33.52847872326639|7.8780844036697255| 23.89795355693433|-4.823576146788991| 23.27838071038045|-0.8821229357798163|19.800566979036457|13.500678899082558|15.082220582302337|\n",
      "+-------+--------+---------+----+----+--------------+------------------+------------------+-----------------+-------------------+------------------+-------------------+------------------+-------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lista para guardar los features\n",
    "data = []\n",
    "metadata_list = []  # OJO cambiamos el nombre de la lista de metadatos\n",
    "\n",
    "\n",
    "def extract_features(path):\n",
    "    try:\n",
    "        h5 = GETTERS.open_h5_file_read(path)\n",
    "        segments_timbre = GETTERS.get_segments_timbre(h5)\n",
    "        if segments_timbre is None or len(segments_timbre) == 0:\n",
    "            timbre_mean = [0.0] * 12\n",
    "            timbre_std = [0.0] * 12\n",
    "        else:\n",
    "            timbre_mean = np.mean(segments_timbre, axis=0).tolist()\n",
    "            timbre_std = np.std(segments_timbre, axis=0).tolist()\n",
    "\n",
    "        features = {\n",
    "            'tempo': float(GETTERS.get_tempo(h5)),\n",
    "            'loudness': float(GETTERS.get_loudness(h5)),\n",
    "            'duration': float(GETTERS.get_duration(h5)),\n",
    "            'key': float(GETTERS.get_key(h5)),\n",
    "            'mode': float(GETTERS.get_mode(h5)),\n",
    "            'time_signature': float(GETTERS.get_time_signature(h5)),\n",
    "            'song_id': GETTERS.get_song_id(h5).decode('utf-8')\n",
    "        }\n",
    "\n",
    "        for i in range(12):\n",
    "            features[f'timbre_mean_{i}'] = timbre_mean[i]\n",
    "            features[f'timbre_std_{i}'] = timbre_std[i]\n",
    "\n",
    "        song_id = GETTERS.get_song_id(h5).decode('utf-8')\n",
    "        title = GETTERS.get_title(h5).decode('utf-8')\n",
    "        artist = GETTERS.get_artist_name(h5).decode('utf-8')\n",
    "\n",
    "        meta = {\n",
    "            'song_id': song_id,\n",
    "            'title': title,\n",
    "            'artist': artist\n",
    "        }\n",
    "\n",
    "        h5.close()\n",
    "\n",
    "        return features, meta\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando el fichero: {path} --> {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# Recorremos los ficheros uno a uno\n",
    "for path in file_paths:\n",
    "    result, meta = extract_features(path)\n",
    "    if result is not None:\n",
    "        data.append(result)\n",
    "    if meta is not None:\n",
    "        metadata_list.append(meta)\n",
    "\n",
    "# Convertimos las listas a pandas\n",
    "df_pd = pd.DataFrame(data)\n",
    "df_meta = pd.DataFrame(metadata_list)\n",
    "\n",
    "# Guardamos los metadatos\n",
    "df_meta.to_csv(\"songs_metadata.csv\", index=False)\n",
    "\n",
    "# Y lo convertimos a DataFrame de PySpark\n",
    "df = spark.createDataFrame(df_pd)\n",
    "\n",
    "# Visualizamos los primeros registros\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c02db8",
   "metadata": {},
   "source": [
    "#### Entrenar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50d5b5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/17 18:21:38 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/06/17 18:21:38 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "feature_cols = ['tempo', 'loudness', 'duration', 'key', 'mode', 'time_signature'] + \\\n",
    "               [f'timbre_mean_{i}' for i in range(12)] + \\\n",
    "               [f'timbre_std_{i}' for i in range(12)]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_vec\")\n",
    "df_assembled = assembler.transform(df)\n",
    "\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features_vec\", outputCol=\"scaled_features\")\n",
    "scaler_model = scaler.fit(df_assembled)\n",
    "df_scaled = scaler_model.transform(df_assembled)\n",
    "\n",
    "\n",
    "kmeans = KMeans(featuresCol='scaled_features',\n",
    "                predictionCol='cluster_id', k=20, seed=42)\n",
    "model = kmeans.fit(df_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44e23fa",
   "metadata": {},
   "source": [
    "#### Recomendación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2c52cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La nueva canción ha sido asignada al cluster: 15\n",
      "+------------------+\n",
      "|           song_id|\n",
      "+------------------+\n",
      "|SOHODRU12A81C230CE|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.clustering import KMeansModel\n",
    "\n",
    "# Supongamos que tienes ya definido:\n",
    "# model, scaler_model, assembler, df_scaled\n",
    "\n",
    "# Simulamos la nueva canción\n",
    "new_song = {\n",
    "    'tempo': 120.0,\n",
    "    'loudness': -5.0,\n",
    "    'duration': 210.0,\n",
    "    'key': 2.0,\n",
    "    'mode': 1.0,\n",
    "    'time_signature': 4.0,\n",
    "    'song_id': 'NEW_SONG_ID'\n",
    "}\n",
    "\n",
    "# Simulamos timbre features\n",
    "for i in range(12):\n",
    "    new_song[f'timbre_mean_{i}'] = np.random.uniform(-50, 50)\n",
    "    new_song[f'timbre_std_{i}'] = np.random.uniform(10, 50)\n",
    "\n",
    "# Convertimos a Spark DataFrame\n",
    "new_song_df_pd = pd.DataFrame([new_song])\n",
    "new_song_df = spark.createDataFrame(new_song_df_pd)\n",
    "\n",
    "#  Ensamblamos y escalamos usando el pipeline original\n",
    "new_song_vec = assembler.transform(new_song_df)\n",
    "new_song_scaled = scaler_model.transform(new_song_vec)\n",
    "\n",
    "# Hacemos la predicción de cluster\n",
    "new_song_pred = model.transform(new_song_scaled)\n",
    "predicted_cluster = new_song_pred.select(\n",
    "    \"cluster_id\").collect()[0][\"cluster_id\"]\n",
    "\n",
    "print(f\"La nueva canción ha sido asignada al cluster: {predicted_cluster}\")\n",
    "\n",
    "# Buscamos canciones del dataset original en el mismo cluster\n",
    "\n",
    "# Si no habías guardado los clusters en el df original:\n",
    "df_with_cluster = model.transform(df_scaled)\n",
    "\n",
    "# Filtramos por el mismo cluster\n",
    "similar_songs = df_with_cluster.filter(\n",
    "    df_with_cluster.cluster_id == predicted_cluster)\n",
    "\n",
    "# Mostramos algunas recomendaciones (por ejemplo 3)\n",
    "similar_songs.select(\"song_id\").limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e393b07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               song_id    title                artist\n",
      "15  SOHODRU12A81C230CE  Genuine  Five Fingers of Funk\n"
     ]
    }
   ],
   "source": [
    "metadata_df = pd.read_csv(\"songs_metadata.csv\")\n",
    "\n",
    "# Supongamos que estos son los song_ids recomendados que has obtenido de tu modelo\n",
    "recommended_song_ids = [row['song_id']\n",
    "                        for row in similar_songs.select(\"song_id\").limit(3).collect()]\n",
    "\n",
    "\n",
    "# Filtramos los metadatos para obtener nombre de la canción y artista\n",
    "recommended_songs = metadata_df[metadata_df['song_id'].isin(\n",
    "    recommended_song_ids)]\n",
    "\n",
    "# Mostramos el resultado\n",
    "print(recommended_songs[['song_id', 'title', 'artist']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f30e57-1340-4091-8d16-11db1651e830",
   "metadata": {},
   "source": [
    "#### Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99cb0aeb-4053-4ec8-8da4-98415c8bc491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Creamos el pipeline con los stages que usaste durante el entrenamiento\n",
    "pipeline = Pipeline(stages=[assembler, scaler, kmeans])\n",
    "\n",
    "# Lo ajustamos sobre el dataframe ya escalado\n",
    "pipeline_model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fd466de-82ae-406b-b55e-efeea7466356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipeline_model.write().overwrite().save(\"file:///models/music-recommender-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c2d496-ab86-4701-8c28-3d58d71d5d94",
   "metadata": {},
   "source": [
    "#### Cargar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97416655-e5ad-4943-a375-bbd1213edb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "loaded_model = PipelineModel.load(\"file:///models/music-recommender-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4cf9657-20ad-4476-84be-0e5d5445ae47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La nueva canción ha sido asignada al cluster: 15\n",
      "+------------------+\n",
      "|           song_id|\n",
      "+------------------+\n",
      "|SOHODRU12A81C230CE|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_song = {\n",
    "    'tempo': 120.0,\n",
    "    'loudness': -5.0,\n",
    "    'duration': 210.0,\n",
    "    'key': 8.0,\n",
    "    'mode': 1.0,\n",
    "    'time_signature': 4.0,\n",
    "    'song_id': 'NEW_SONG_ID'\n",
    "}\n",
    "\n",
    "new_song_pred = model.transform(new_song_scaled)\n",
    "predicted_cluster = new_song_pred.select(\n",
    "    \"cluster_id\").collect()[0][\"cluster_id\"]\n",
    "\n",
    "print(f\"La nueva canción ha sido asignada al cluster: {predicted_cluster}\")\n",
    "\n",
    "# Buscamos canciones del dataset original en el mismo cluster\n",
    "\n",
    "# Si no habías guardado los clusters en el df original:\n",
    "df_with_cluster = model.transform(df_scaled)\n",
    "\n",
    "# Filtramos por el mismo cluster\n",
    "similar_songs = df_with_cluster.filter(\n",
    "    df_with_cluster.cluster_id == predicted_cluster)\n",
    "\n",
    "# Mostramos algunas recomendaciones (por ejemplo 3)\n",
    "similar_songs.select(\"song_id\").limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31f0dab7-bf80-45f2-8118-91b9f18bf12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               song_id    title                artist\n",
      "15  SOHODRU12A81C230CE  Genuine  Five Fingers of Funk\n"
     ]
    }
   ],
   "source": [
    "metadata_df = pd.read_csv(\"songs_metadata.csv\")\n",
    "\n",
    "# Supongamos que estos son los song_ids recomendados que has obtenido de tu modelo\n",
    "recommended_song_ids = [row['song_id']\n",
    "                        for row in similar_songs.select(\"song_id\").limit(3).collect()]\n",
    "\n",
    "\n",
    "# Filtramos los metadatos para obtener nombre de la canción y artista\n",
    "recommended_songs = metadata_df[metadata_df['song_id'].isin(\n",
    "    recommended_song_ids)]\n",
    "\n",
    "# Mostramos el resultado\n",
    "print(recommended_songs[['song_id', 'title', 'artist']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5f62e-98a3-4497-95a0-57adae882f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
